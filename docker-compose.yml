version: '3.8'

services:
  # OpenSIPS AI Voice Connector (OAVC - Ana uygulama)
  opensips-ai-voice-connector:
    build: .
    container_name: opensips-ai-voice-connector
    ports:
      - "8088:8088/tcp"
      - "8089:8089/tcp"
      - "35000-35003:35000-35003/udp"
      - "35010:35010/udp"
      - "35011:35011/udp"
    volumes:
      - ./cfg/opensips-ai-voice-connector.ini:/app/cfg/opensips-ai-voice-connector.ini
      - ./test_audio:/app/test_audio
    environment:
      - CONFIG_FILE=/app/cfg/opensips-ai-voice-connector.ini
      - PYTHONPATH=/app
      - VOSK_SERVER_URL=ws://vosk-server:2700
      - PIPER_TTS_URL=ws://piper-tts-server:8000/tts
      - LLAMA_SERVER_URL=ws://llm-turkish-server:8765
    networks:
      - opensips_network
    depends_on:
      - opensips
      - vosk-server
      - piper-tts-server
      - llm-turkish-server
    restart: unless-stopped

  # OpenSIPS SIP Proxy
  opensips:
    image: opensips/opensips:3.6
    container_name: opensips
    ports:
      - "5060:5060/udp"
      - "5060:5060/tcp"
      - "8080:8080/udp"
    volumes:
      - ./cfg/opensips.cfg:/etc/opensips/opensips.cfg
    networks:
      - opensips_network
    restart: unless-stopped

  # Vosk STT Server
  vosk-server:
    image: dehalokmansahin/vosk-server:latest
    container_name: vosk-server
    ports:
      - "2700:2700"
    environment:
      - MODEL_PATH=/opt/vosk-model
      - SAMPLE_RATE=16000
    networks:
      - opensips_network
    restart: unless-stopped

  # Piper TTS Server
  piper-tts-server:
    image: piper-tts-server:py311
    container_name: piper-tts-server
    ports:
      - "8000:8000"
      - "8001:8001"
    environment:
      - MODEL_PATH=/app/models
      - VOICE_MODEL=tr_TR-dfki-medium
    volumes:
      - piper_models:/app/models
    networks:
      - opensips_network
    restart: unless-stopped

  # LLM Turkish Server (Llama3.2 Turkish Model)
  llm-turkish-server:
    image: dehalokmansahin/llm-turkish-server:latest
    container_name: llm-turkish-server
    ports:
      - "8765:8765"
    environment:
      - MODEL_NAME=llama3.2:3b-instruct-turkish
      - MAX_TOKENS=80
      - TEMPERATURE=0.2
      - TOP_P=0.7
      - WEBSOCKET_PORT=8765
    volumes:
      - llm_models:/app/models
      - llm_cache:/app/cache
    networks:
      - opensips_network
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped

networks:
  opensips_network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

volumes:
  piper_models:
    driver: local
  llm_models:
    driver: local
  llm_cache:
    driver: local
  model_data:
    driver: local
