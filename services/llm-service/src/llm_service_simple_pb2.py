# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# NO CHECKED-IN PROTOBUF GENCODE
# source: llm_service_simple.proto
# Protobuf Python Version: 6.31.1
"""Generated protocol buffer code."""
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import runtime_version as _runtime_version
from google.protobuf import symbol_database as _symbol_database
from google.protobuf.internal import builder as _builder
_runtime_version.ValidateProtobufRuntimeVersion(
    _runtime_version.Domain.PUBLIC,
    6,
    31,
    1,
    '',
    'llm_service_simple.proto'
)
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()


from google.protobuf import empty_pb2 as google_dot_protobuf_dot_empty__pb2


DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x18llm_service_simple.proto\x12\x0fopensips.ai.llm\x1a\x1bgoogle/protobuf/empty.proto\"\x82\x01\n\x15TextProcessingRequest\x12\x0c\n\x04text\x18\x01 \x01(\t\x12\x15\n\rsystem_prompt\x18\x02 \x01(\t\x12\x13\n\x0btemperature\x18\x03 \x01(\x02\x12\x12\n\nmax_tokens\x18\x04 \x01(\x05\x12\r\n\x05top_p\x18\x05 \x01(\x02\x12\x0c\n\x04stop\x18\x06 \x03(\t\"+\n\x0cTextResponse\x12\r\n\x05\x63hunk\x18\x01 \x01(\t\x12\x0c\n\x04\x64one\x18\x02 \x01(\x08\"\x9f\x01\n\x14\x43ontextUpdateRequest\x12\x12\n\nsession_id\x18\x01 \x01(\t\x12\x43\n\x07updates\x18\x02 \x03(\x0b\x32\x32.opensips.ai.llm.ContextUpdateRequest.UpdatesEntry\x1a.\n\x0cUpdatesEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\"3\n\x0f\x43ontextResponse\x12\x0f\n\x07success\x18\x01 \x01(\x08\x12\x0f\n\x07message\x18\x02 \x01(\t\"\xa4\x01\n\x0eHealthResponse\x12\x36\n\x06status\x18\x01 \x01(\x0e\x32&.opensips.ai.llm.HealthResponse.Status\x12\x0f\n\x07message\x18\x02 \x01(\t\x12\x14\n\x0cmodel_loaded\x18\x03 \x01(\t\"3\n\x06Status\x12\x0b\n\x07UNKNOWN\x10\x00\x12\x0b\n\x07SERVING\x10\x01\x12\x0f\n\x0bNOT_SERVING\x10\x02\"S\n\rStatsResponse\x12\x16\n\x0etotal_requests\x18\x01 \x01(\x05\x12\x16\n\x0euptime_seconds\x18\x02 \x01(\x03\x12\x12\n\nmodel_info\x18\x03 \x01(\t2\xca\x02\n\nLLMService\x12V\n\x0bProcessText\x12&.opensips.ai.llm.TextProcessingRequest\x1a\x1d.opensips.ai.llm.TextResponse0\x01\x12X\n\rUpdateContext\x12%.opensips.ai.llm.ContextUpdateRequest\x1a .opensips.ai.llm.ContextResponse\x12\x46\n\x0bHealthCheck\x12\x16.google.protobuf.Empty\x1a\x1f.opensips.ai.llm.HealthResponse\x12\x42\n\x08GetStats\x12\x16.google.protobuf.Empty\x1a\x1e.opensips.ai.llm.StatsResponseB2Z0github.com/opensips/ai-voice-connector/proto/llmb\x06proto3')

_globals = globals()
_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'llm_service_simple_pb2', _globals)
if not _descriptor._USE_C_DESCRIPTORS:
  _globals['DESCRIPTOR']._loaded_options = None
  _globals['DESCRIPTOR']._serialized_options = b'Z0github.com/opensips/ai-voice-connector/proto/llm'
  _globals['_CONTEXTUPDATEREQUEST_UPDATESENTRY']._loaded_options = None
  _globals['_CONTEXTUPDATEREQUEST_UPDATESENTRY']._serialized_options = b'8\001'
  _globals['_TEXTPROCESSINGREQUEST']._serialized_start=75
  _globals['_TEXTPROCESSINGREQUEST']._serialized_end=205
  _globals['_TEXTRESPONSE']._serialized_start=207
  _globals['_TEXTRESPONSE']._serialized_end=250
  _globals['_CONTEXTUPDATEREQUEST']._serialized_start=253
  _globals['_CONTEXTUPDATEREQUEST']._serialized_end=412
  _globals['_CONTEXTUPDATEREQUEST_UPDATESENTRY']._serialized_start=366
  _globals['_CONTEXTUPDATEREQUEST_UPDATESENTRY']._serialized_end=412
  _globals['_CONTEXTRESPONSE']._serialized_start=414
  _globals['_CONTEXTRESPONSE']._serialized_end=465
  _globals['_HEALTHRESPONSE']._serialized_start=468
  _globals['_HEALTHRESPONSE']._serialized_end=632
  _globals['_HEALTHRESPONSE_STATUS']._serialized_start=581
  _globals['_HEALTHRESPONSE_STATUS']._serialized_end=632
  _globals['_STATSRESPONSE']._serialized_start=634
  _globals['_STATSRESPONSE']._serialized_end=717
  _globals['_LLMSERVICE']._serialized_start=720
  _globals['_LLMSERVICE']._serialized_end=1050
# @@protoc_insertion_point(module_scope)
