#!/usr/bin/env python3
"""
Ultra-Fast TÃ¼rkÃ§e LLM Test
"""

import sys
import os
import time
import asyncio

# Python path ekle
current_dir = os.path.dirname(os.path.abspath(__file__))
src_path = os.path.join(current_dir, "src")
pipecat_src_path = os.path.join(current_dir, "pipecat", "src")

if src_path not in sys.path:
    sys.path.insert(0, src_path)
if pipecat_src_path not in sys.path:
    sys.path.insert(0, pipecat_src_path)

# soxr stub
import numpy as np
if not hasattr(sys.modules, 'soxr'):
    class SoxrStub:
        def resample(self, *args, **kwargs):
            return np.array([])
    sys.modules['soxr'] = SoxrStub()

from services.ollama_llm import OllamaLLMService

async def test_ultra_fast_turkish():
    """Ultra-fast TÃ¼rkÃ§e optimizasyonlarÄ± test et"""
    
    print("ğŸš€ Ultra-Fast TÃ¼rkÃ§e LLM Test")
    print("=" * 40)
    print("ğŸ¯ Hedef: â‰¤400ms first token")
    print("ğŸ”§ Optimizasyonlar:")
    print("   â€¢ Temperature: 0.2 (ultra tutarlÄ±)")
    print("   â€¢ Top_p: 0.7 (hÄ±zlÄ± karar)")
    print("   â€¢ Max tokens: 50 (ultra kÄ±sa)")
    print("   â€¢ Context: 1024 (kÃ¼Ã§Ã¼k)")
    print("   â€¢ Timeout: 2s (agresif)")
    print()
    
    service = OllamaLLMService()
    await service.start()
    
    # HÄ±zlÄ± test senaryolarÄ±
    fast_test_cases = [
        "Merhaba",
        "Kredi kartÄ±",
        "Hesap bakiye",
        "TeÅŸekkÃ¼rler",
        "YardÄ±m",
    ]
    
    under_400ms_count = 0
    total_tests = len(fast_test_cases)
    
    for i, test_input in enumerate(fast_test_cases, 1):
        print(f"âš¡ Test {i}: {test_input}")
        
        start_time = time.time()
        first_token_time = None
        response_text = ""
        
        print("ğŸ¤– ", end="", flush=True)
        
        try:
            async for token in service.generate_response_streaming(test_input):
                if first_token_time is None:
                    first_token_time = time.time()
                    first_token_latency = (first_token_time - start_time) * 1000
                    
                    # Renk kodlamasÄ±
                    if first_token_latency <= 400:
                        color = "ğŸŸ¢"  # YeÅŸil - baÅŸarÄ±lÄ±
                        under_400ms_count += 1
                    elif first_token_latency <= 600:
                        color = "ğŸŸ¡"  # SarÄ± - kabul edilebilir
                    else:
                        color = "ğŸ”´"  # KÄ±rmÄ±zÄ± - yavaÅŸ
                    
                    print(f"{color}[{first_token_latency:.0f}ms] ", end="", flush=True)
                
                print(token, end="", flush=True)
                response_text += token
            
            end_time = time.time()
            total_time = (end_time - start_time) * 1000
            print(f" [{total_time:.0f}ms]")
            
        except Exception as e:
            print(f"âŒ Hata: {e}")
    
    # SonuÃ§lar
    success_rate = (under_400ms_count / total_tests) * 100
    
    print(f"\nğŸ“Š Ultra-Fast SonuÃ§larÄ±:")
    print(f"   ğŸ¯ â‰¤400ms BaÅŸarÄ±: {under_400ms_count}/{total_tests} ({success_rate:.1f}%)")
    
    if success_rate >= 80:
        print("   ğŸ‰ MÃœKEMMEL! Hedef baÅŸarÄ±yla ulaÅŸÄ±ldÄ±!")
    elif success_rate >= 60:
        print("   âœ… Ä°YÄ°! Hedef bÃ¼yÃ¼k Ã¶lÃ§Ã¼de baÅŸarÄ±ldÄ±!")
    elif success_rate >= 40:
        print("   âš ï¸ ORTA! Daha fazla optimizasyon gerekli!")
    else:
        print("   âŒ DÃœÅÃœK! Ciddi optimizasyon gerekli!")
    
    await service.stop()

async def test_specific_optimizations():
    """Spesifik optimizasyon senaryolarÄ±"""
    
    print(f"\nğŸ”¬ Spesifik Optimizasyon Testleri")
    print("=" * 35)
    
    service = OllamaLLMService()
    await service.start()
    
    # Spesifik senaryolar
    scenarios = [
        {
            "name": "Basit Selamlama",
            "input": "Merhaba",
            "expected_tokens": ["Merhaba", "Size", "nasÄ±l", "yardÄ±mcÄ±"]
        },
        {
            "name": "Kredi KartÄ±",
            "input": "Kredi kartÄ± baÅŸvurusu",
            "expected_tokens": ["Tabii", "kredi", "kartÄ±", "baÅŸvuru"]
        },
        {
            "name": "Hesap Bilgi",
            "input": "Hesap bakiyem",
            "expected_tokens": ["Hesap", "bakiye", "iÃ§in", "bilgi"]
        }
    ]
    
    for scenario in scenarios:
        print(f"\nğŸ­ {scenario['name']}: {scenario['input']}")
        
        start_time = time.time()
        first_token_time = None
        tokens_received = []
        
        print("ğŸ¤– ", end="", flush=True)
        
        try:
            async for token in service.generate_response_streaming(scenario['input']):
                if first_token_time is None:
                    first_token_time = time.time()
                    first_token_latency = (first_token_time - start_time) * 1000
                    print(f"[{first_token_latency:.0f}ms] ", end="", flush=True)
                
                tokens_received.append(token.strip())
                print(token, end="", flush=True)
            
            end_time = time.time()
            total_time = (end_time - start_time) * 1000
            print(f" [{total_time:.0f}ms]")
            
            # Beklenen token analizi
            response_text = "".join(tokens_received)
            expected_found = sum(1 for expected in scenario['expected_tokens'] 
                               if expected.lower() in response_text.lower())
            
            print(f"   ğŸ“ Beklenen kelimeler: {expected_found}/{len(scenario['expected_tokens'])}")
            
        except Exception as e:
            print(f"   âŒ Hata: {e}")
    
    await service.stop()

if __name__ == "__main__":
    print("ğŸš€ Ultra-Fast TÃ¼rkÃ§e LLM Optimization Suite")
    print("=" * 50)
    
    asyncio.run(test_ultra_fast_turkish())
    asyncio.run(test_specific_optimizations())
    
    print(f"\nğŸ¯ Ultra-Fast Optimizasyon Ã–zeti:")
    print("âœ… Temperature: 0.2 â†’ Ultra tutarlÄ± TÃ¼rkÃ§e")
    print("âœ… Top_p: 0.7 â†’ HÄ±zlÄ± ve odaklÄ± kararlar")
    print("âœ… Max tokens: 50 â†’ Ultra kÄ±sa yanÄ±tlar")
    print("âœ… Context: 1024 â†’ KÃ¼Ã§Ã¼k ve hÄ±zlÄ±")
    print("âœ… Timeout: 2s â†’ Agresif zaman limiti")
    print("âœ… Early stopping â†’ Noktalama ile dur")
    print("âœ… ChatML format â†’ Structured prompting")
    
    print(f"\nğŸ† Hedef: 400ms first token latency!") 