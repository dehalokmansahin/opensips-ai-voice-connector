# Story 0.1: Remove LLM Service Dependencies

## Status
Draft

## Story
**As a** system architect,  
**I want** to remove the LLM service and all its dependencies from the system,  
**so that** I can simplify the architecture and eliminate GPU requirements for the IVR testing transformation.

## Acceptance Criteria
1. Remove LLM service container from docker-compose.yml
2. Remove LLM service dependencies from core application
3. Remove LLM-related gRPC clients and protobuf definitions
4. Remove LLM model storage and GPU-related configurations
5. Verify existing ASR/TTS services continue to function normally

## Tasks / Subtasks
- [ ] Remove LLM service from docker-compose.yml (AC: 1)
  - [ ] Delete llm-service container definition
  - [ ] Remove LLM service dependency from core service
  - [ ] Remove LLM model volume mounts
- [ ] Clean up core application LLM integration (AC: 2)
  - [ ] Remove LLM client from grpc_clients directory
  - [ ] Remove LLM service references from service registry
  - [ ] Update core application configuration
- [ ] Remove LLM protobuf definitions (AC: 3)
  - [ ] Delete LLM service protobuf files
  - [ ] Update protobuf generation scripts
  - [ ] Clean up generated LLM gRPC files
- [ ] Remove LLM models and GPU configurations (AC: 4)
  - [ ] Remove LLM model directory and files
  - [ ] Remove GPU-related environment variables
  - [ ] Remove CUDA dependencies from requirements
- [ ] Verify system functionality (AC: 5)
  - [ ] Test ASR service independently
  - [ ] Test TTS service independently
  - [ ] Verify core application starts without LLM
  - [ ] Run existing test suite

## Dev Notes

### Relevant Source Tree Info
- **LLM Service Location**: `services/llm-service/` - entire directory to be removed
- **Core Integration**: `core/grpc_clients/llm_client.py` - remove file
- **Docker Configuration**: `docker-compose.yml` - remove llm-service section
- **Model Storage**: `models/llm/` - remove directory
- **Protobuf**: `shared/proto/llm_service*.proto` - remove files

### Architecture Context
This refactoring prepares the system for IVR testing by eliminating conversational AI components. The LLM service is being replaced by simple intent recognition in Epic 2. This change reduces system complexity and resource requirements while maintaining existing ASR/TTS functionality.

### Integration Points
- Preserve ASR service (port 50051) for IVR response transcription
- Preserve TTS service (port 50053) for IVR prompt generation  
- Maintain existing service health checks and networking
- Keep existing RTP audio processing capabilities

### Testing
**Test File Location**: `tests/test_llm_removal.py` (new file)
**Test Standards**: pytest framework with existing patterns
**Testing Framework**: Use existing pytest configuration and test utilities
**Specific Requirements**: 
- Verify ASR/TTS services function independently
- Confirm no LLM service startup attempts
- Validate core application health without LLM

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|---------|
| 2025-01-27 | 1.0 | Initial story creation | System Architect |

## Dev Agent Record
*This section will be populated by the development agent during implementation*

## QA Results
*Results from QA Agent review will be added here*